# October 2024

## 10/19/2024

I started this diary section in the project. I'm planning on having a markdown file for each month. I will use this to track my progress on the project and my thinking.

### M2 Max laptop arrives

My M2 Max arrived today. This is replacing my M2 Air. The machine has 96GB of RAM and a 38 core GPU. The better screen
and the ability to run local LLMs much faster are the primary reasons for the change.

I restored my latest time machine backup to the new machine and started up vscode. I made changes to allow Python 3.12 to be the base
level for the project. This required some changes in the test cases as assertEquals is no longer available.

### Bootstrap DataPlatform sprint

The project is up and running now and I'm hoping to do a Sprint to get back to the project. I would like to get the first DataPlatform running over the next month. This will be a big milestone for the project. The plan is to do a local one. I have 2 large machines to host it locally. I have my M2 Max
with 96GB of RAM which is a good spot for Docker containers and I have my Dell 7090 which has 128GB of RAM, 10 cores and 8TB of SSDs running proxmox. This
is plenty of resources to get the platform running. Docker swarm is my likely container platform for these.

I am planning on using the following stack:

* AirFlow for job scheduling
* Postgres for database sources
* Debenzium for CDC
* Spark 4.0 and iceberg for data processing and storage.
* Live data only and milestoned data will be supported.
* Minio for local S3 storage
* Consumers can query data from iceberg using Spark OR from postgres databases when thats more appropriate.

I'm antipicating scaling problems with AirFlow but that said I would have the same issues with AWS Glue or Microsoft Data Factory. They do not seem
to scale to large job graphs (more than a 100). The job graph for my last job was likely almost a million jobs. The platforms will need to factor
the job graph in to decoupled sections which these scheduling tools can handle.

## 10/20/2024


