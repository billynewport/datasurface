# March 2025

## 2025/03/04

The schema reconciler. This is a standard service used by DataPlatforms to make sure the tables and views in a data base match the schemas in the DataSurface model. This would typically be called before an operation to update data in a table. Therefore, it is a service which takes a DataPlatform instance, a credential and the Workspace/Datasetgroup containing the datasets to reconcile. The intention graph has a set of graphs keys by the DataPlatform instance. It also has a list of DSG's per DataContainer. I'm going to try a simply python job using sqlachemy and SQL to start with. This will work and be tested on Postgres and hopefully will work on cloud databases like Snowflake/Redshift also. I'll try to avoid Spark for now.

Worked with claude to start getting a postgres instance running in github actions and locally. Adding a conftest.py file to initialize a fixture for the tests which need postgres accessto run.

Tests using the database should have a db_engine parameter and ones which want a clean database should have a test_db parameter.

## 2025/03/11

About to get on a plane to New Zealand tonight. Learning more about cursor rules and how to use it. I think it'll make a difference to how effective the AI tools are.

## 2025/03/12

### Schema management and making it flexible enough

Pipeline developers usually don't appreciate this enough as they target a single tech stack. We need to support multiple technologies over time. We need a way to map datasets to a DataContainer and take into account differences between DataContainers. PostGres and Iceberg tables for example will have differences in identifier naming, datatypes supported and so on. Sometimes even differences between Postgres or iceberg versions, new datatypes added for example. DataSurface needs to work with multiple technologies and versions of those concurrently.

Working on the code to create and maintain the schemas of objects in a DataContainer. The DataContainer will always place its constraints on a data platform. Naming limitations, length of identifiers, reserved words, reserved characters, case sensitivity. DataTypes also need from the model type to the DataContainer type even if its supported. I had some of this prototyped before but now I want to flesh it out and make it work with the first postgres container.

This also requires lint time checks, when the model is modified. If a specific DataContainer is chosen by or for a consumer then the datasets required by that consumer must be compatible with the selected DataContainer or at least mappable through a conversion. This really needs a tool, like an extension for vscode which keeps a local copy of the current latest model and constantly compares it to the current model or does it on demand and previews the action failures before attempting a push to the main branch.

### VsCode DataSurface extension

I've started exploring how I'd write this extension. Working with cursor, it looks straightforward. It's basically a wrapper around the existing code used during a merge operation in the action handlers. Vscode makes it easy to flag warnings and errors against the python code creating the DSL objects with the issues.