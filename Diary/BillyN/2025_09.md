# September 2025

## 2025/09/01

Working on getting it working on AWS today using EKS. Pointed my local kubectl to the EKS cluster and doing the bring using local shells.

Having trouble with far gate. Switching to EC2. Problems are mainly with efs-sc. So far, experience with AWS is poor. It's very slow. Deleting clusters and so on takes over 20 minutes. I don't know if this is normal.

Frustrating day. AWS is crazy slow at provisioning or changing resources. I spent the whole day trying to start an EKS cluster. It would come up and then I'd discover something wrong with it and then I needed to do it all over again. Very slow loop. I'm currently making an EKS cluster with m5.4xlarge nodes. I tried smaller nodes but the airflow pods need more than the small ones I was using and I will still need to run the datasurface jobs so the node group is up to 5 nodes, 2 desired. The last issue of the day was I hit a vcore quota after waiting nearly an hour for it to tell me. I've asked for a quota increase to 48 vcores but the day is gone now. It'll be Wed before I can continue. I'm using claude 4 sonnet in cursor to help with this but it's struggling with the yaml files.

### Security implementation

I'm thinking through an initial security implementation. I'll implement for postgres, local kubernetes and AWS to start. This is tomorrows work while I wait for the vcore quota to be approved. I need to make a new job called postgres_security_sync. This will be launched periodically on airflow and have access to the merge database. I'll need to have a db_security_operations class with different implementations for each database type at least depending on the database.

I would also like a transformer to load the eco model and write the major entities to a Datastore. The transformer will load the model, and write the ecosystem to its dataset, datastores, datasets, Workspaces, DataTransformers, Teams, GovernanceZones. This would be useful as its much more queryable than the Ecomodel in memory. The security module could itself be a transformer to create the transformer users and required read permissions and outputs for example. Another transformer would by the security sync job itself. We would need a way for transformers to run with an AWS IAM role so they can update secrets in AWS Secrets Manager for example.

I need to define a datasurface method to create the output Datastore for people to use in their models. Maybe, the whole DataTransformer is returned by the method to include in the model Workspace. Maybe the whole Workspace.

Use dataclasses and sqlalchemy to define the model.

## 2025/09/03

Adding in support for builtin system artifacts. There are Workspaces, DataTransformers and Datastores which are automatically added to Ecosystems by DataSurface. These includes Datastores which contain the major entities of the Ecosystem model. These Datastores are ingested to the system and are available to use
by devops and other DataTransformers. The ability to run SQL queries to find out about the model is a useful feature in general.

This also created work to allows different kinds of Code Artifacts to be supported in Yellow. I'm debating whether security should be implemented by a DataTransformer on the builtin datastores.

This also helps test self referencing DataTransformers. This is a DataTransformer whose Workspace contains DatasetSinks referencing the output DataStore of the DataTransformer.

## 2025/09/04

The model externalization is now working and a test of it is passing. 

### Returning to AWS

AWS just approved the vcore quote increase to 48 vcores so I'm back on that now.





